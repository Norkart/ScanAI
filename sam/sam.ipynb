{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Installer nødvendige dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q 'git+https://github.com/facebookresearch/segment-anything.git'\n",
    "!pip install -q jupyter_bbox_widget roboflow dataclasses-json supervision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importer nødvendige pakker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import torch\n",
    "import numpy as np\n",
    "import supervision as sv\n",
    "from segment_anything import sam_model_registry, SamAutomaticMaskGenerator, SamPredictor\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import mode\n",
    "from supervision.draw.color import Color, ColorPalette\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sett opp SAM modellen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "#CHECKPOINT_PATH = \"models/sam_vit_b_01ec64.pth\"\n",
    "#MODEL_TYPE = \"vit_b\"\n",
    "\n",
    "#CHECKPOINT_PATH = \"models/sam_vit_l_0b3195.pth\"\n",
    "#MODEL_TYPE = \"vit_l\"\n",
    "\n",
    "CHECKPOINT_PATH = \"models/sam_vit_h_4b8939.pth\"\n",
    "MODEL_TYPE = \"vit_h\"\n",
    "\n",
    "sam = sam_model_registry[MODEL_TYPE](checkpoint=CHECKPOINT_PATH).to(device=DEVICE)\n",
    "mask_generator = SamAutomaticMaskGenerator(\n",
    "    model=sam,\n",
    "    points_per_side=32,                 # Controls the sampling density\n",
    "    pred_iou_thresh=0.9,                # Increase to filter out low-quality masks\n",
    "    stability_score_thresh=0.95,        # Increase to keep only stable masks\n",
    "    stability_score_offset=1.0,         # Adjust for stability calculations\n",
    "    box_nms_thresh=0.1,                 # Decrease to reduce overlapping masks\n",
    "    crop_n_layers=1,                    # Reduce complexity\n",
    "    crop_nms_thresh=0.5,                # Adjust NMS threshold for crops\n",
    "    min_mask_region_area=5000,          # Increase to filter out small masks (in pixels)\n",
    "    output_mode=\"binary_mask\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sett opp bildet du vil segmentere og segmenter det ved bruk av sam."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_PATH = \"datasets/aalesund/1504200/200.jpg\"\n",
    "scale_percent = 30\n",
    "\n",
    "image_bgr = cv2.imread(IMAGE_PATH)\n",
    "\n",
    "width = int(image_bgr.shape[1] * scale_percent / 100)\n",
    "height = int(image_bgr.shape[0] * scale_percent / 100)\n",
    "new_dim = (width, height)\n",
    "\n",
    "image_bgr = cv2.resize(image_bgr, new_dim, interpolation=cv2.INTER_AREA)\n",
    "image_rgb = cv2.cvtColor(image_bgr, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "sam_result = mask_generator.generate(image_rgb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definer hjelpe funksjoner får å sjekke om en maske er inne i en annen, og finne mest vanlige farge til masken."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_mask_inside(outer_mask, inner_mask):\n",
    "    return np.all(outer_mask[inner_mask > 0])\n",
    "\n",
    "def custom_mode(array):\n",
    "    values, counts = np.unique(array, return_counts=True)\n",
    "    return values[np.argmax(counts)]\n",
    "\n",
    "def get_most_common_color(image_bgr, mask):\n",
    "    mask_area = np.where(mask)\n",
    "    pixels = image_bgr[mask_area]\n",
    "    if pixels.size == 0 or pixels.ndim != 2 or pixels.shape[1] != 3:\n",
    "        return (0, 0, 0)\n",
    "\n",
    "    b_mode = int(custom_mode(pixels[:, 0]))\n",
    "    g_mode = int(custom_mode(pixels[:, 1]))\n",
    "    r_mode = int(custom_mode(pixels[:, 2]))\n",
    "    return (b_mode+50, g_mode+50, r_mode+50)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gjør klar maskene og sett ein threshold for hvor mange masker som kan være inne i en annen før den blir fjernet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "masks_with_areas = [\n",
    "    (i, mask['segmentation'], np.sum(mask['segmentation']))\n",
    "    for i, mask in enumerate(sam_result) if np.any(mask['segmentation'])\n",
    "]\n",
    "\n",
    "masks_with_areas.sort(key=lambda x: x[2], reverse=True) \n",
    "\n",
    "contained_mask_threshold = int(0.5 * len(masks_with_areas))\n",
    "print(f\"Contained Mask Threshold: {contained_mask_threshold}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filtrer maskene."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices_to_remove = set()\n",
    "\n",
    "for i, (outer_idx, outer_mask, outer_area) in enumerate(masks_with_areas):\n",
    "    contained_count = 0 \n",
    "\n",
    "    for inner_idx, inner_mask, inner_area in masks_with_areas[i+1:]:\n",
    "        if is_mask_inside(outer_mask, inner_mask):\n",
    "            contained_count += 1 \n",
    "\n",
    "    if contained_count >= contained_mask_threshold:\n",
    "        indices_to_remove.add(outer_idx)\n",
    "\n",
    "filtered_masks_with_areas = [\n",
    "    (idx, mask, area) for idx, mask, area in masks_with_areas if idx not in indices_to_remove\n",
    "]\n",
    "\n",
    "image_area = image_bgr.shape[0] * image_bgr.shape[1]\n",
    "filtered_masks_with_areas = [\n",
    "    (idx, mask, area) for idx, mask, area in filtered_masks_with_areas if area < image_area\n",
    "]\n",
    "\n",
    "filtered_sam_result = [sam_result[idx] for idx, _, _ in filtered_masks_with_areas]\n",
    "\n",
    "sorted_masks = [mask for _, mask, _ in filtered_masks_with_areas]\n",
    "\n",
    "print(f\"Number of masks after filtering: {len(filtered_masks_with_areas)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generer fargepalett baser på fargene under hver maske."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_mask_colors = [\n",
    "    Color.from_bgr_tuple(get_most_common_color(image_bgr, mask)) for mask in sorted_masks\n",
    "]\n",
    "custom_color_palette = ColorPalette(colors=sorted_mask_colors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Annoter bildet med de forskjellige maskene."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detections = sv.Detections.from_sam(sam_result=filtered_sam_result)\n",
    "mask_annotator = sv.MaskAnnotator(color=custom_color_palette, opacity=0.9)\n",
    "\n",
    "custom_color_lookup = np.arange(len(sorted_mask_colors))\n",
    "\n",
    "try:\n",
    "    annotated_image_with_custom_colors = mask_annotator.annotate(\n",
    "        scene=image_bgr.copy(), \n",
    "        detections=detections,\n",
    "        custom_color_lookup=custom_color_lookup\n",
    "    )\n",
    "except AssertionError as ae:\n",
    "    print(f\"Assertion error: {ae}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error during annotation: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vis det orginale og det annoterte bildet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(cv2.cvtColor(image_bgr, cv2.COLOR_BGR2RGB))  \n",
    "plt.title(\"Original Image\")\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(cv2.cvtColor(annotated_image_with_custom_colors, cv2.COLOR_BGR2RGB)) \n",
    "plt.title(\"Annotated Image with Filtered Masks\")\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
