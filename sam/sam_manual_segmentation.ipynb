{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d9035c60",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-18 08:11:04.023 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
     ]
    }
   ],
   "source": [
    "import streamlit as st\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "from segment_anything import sam_model_registry, SamPredictor\n",
    "from streamlit_drawable_canvas import st_canvas\n",
    "from PIL import Image\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "36d88d92",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-18 08:11:04.075 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
     ]
    }
   ],
   "source": [
    "# Set Streamlit layout to \"wide\" to see the entire image\n",
    "st.set_page_config(layout=\"wide\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2e0c76e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set device\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "005432ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load SAM model\n",
    "# You can switch to 'vit_b' if you still have memory issues\n",
    "CHECKPOINT_PATH = \"weights/sam_vit_l_0b3195.pth\"\n",
    "MODEL_TYPE = \"vit_l\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3eff9d25",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sam(\n",
       "  (image_encoder): ImageEncoderViT(\n",
       "    (patch_embed): PatchEmbed(\n",
       "      (proj): Conv2d(3, 1024, kernel_size=(16, 16), stride=(16, 16))\n",
       "    )\n",
       "    (blocks): ModuleList(\n",
       "      (0-23): 24 x Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        )\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): MLPBlock(\n",
       "          (lin1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (lin2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (neck): Sequential(\n",
       "      (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (1): LayerNorm2d()\n",
       "      (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (3): LayerNorm2d()\n",
       "    )\n",
       "  )\n",
       "  (prompt_encoder): PromptEncoder(\n",
       "    (pe_layer): PositionEmbeddingRandom()\n",
       "    (point_embeddings): ModuleList(\n",
       "      (0-3): 4 x Embedding(1, 256)\n",
       "    )\n",
       "    (not_a_point_embed): Embedding(1, 256)\n",
       "    (mask_downscaling): Sequential(\n",
       "      (0): Conv2d(1, 4, kernel_size=(2, 2), stride=(2, 2))\n",
       "      (1): LayerNorm2d()\n",
       "      (2): GELU(approximate='none')\n",
       "      (3): Conv2d(4, 16, kernel_size=(2, 2), stride=(2, 2))\n",
       "      (4): LayerNorm2d()\n",
       "      (5): GELU(approximate='none')\n",
       "      (6): Conv2d(16, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "    (no_mask_embed): Embedding(1, 256)\n",
       "  )\n",
       "  (mask_decoder): MaskDecoder(\n",
       "    (transformer): TwoWayTransformer(\n",
       "      (layers): ModuleList(\n",
       "        (0-1): 2 x TwoWayAttentionBlock(\n",
       "          (self_attn): Attention(\n",
       "            (q_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (k_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (v_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (out_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "          )\n",
       "          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (cross_attn_token_to_image): Attention(\n",
       "            (q_proj): Linear(in_features=256, out_features=128, bias=True)\n",
       "            (k_proj): Linear(in_features=256, out_features=128, bias=True)\n",
       "            (v_proj): Linear(in_features=256, out_features=128, bias=True)\n",
       "            (out_proj): Linear(in_features=128, out_features=256, bias=True)\n",
       "          )\n",
       "          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): MLPBlock(\n",
       "            (lin1): Linear(in_features=256, out_features=2048, bias=True)\n",
       "            (lin2): Linear(in_features=2048, out_features=256, bias=True)\n",
       "            (act): ReLU()\n",
       "          )\n",
       "          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (cross_attn_image_to_token): Attention(\n",
       "            (q_proj): Linear(in_features=256, out_features=128, bias=True)\n",
       "            (k_proj): Linear(in_features=256, out_features=128, bias=True)\n",
       "            (v_proj): Linear(in_features=256, out_features=128, bias=True)\n",
       "            (out_proj): Linear(in_features=128, out_features=256, bias=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (final_attn_token_to_image): Attention(\n",
       "        (q_proj): Linear(in_features=256, out_features=128, bias=True)\n",
       "        (k_proj): Linear(in_features=256, out_features=128, bias=True)\n",
       "        (v_proj): Linear(in_features=256, out_features=128, bias=True)\n",
       "        (out_proj): Linear(in_features=128, out_features=256, bias=True)\n",
       "      )\n",
       "      (norm_final_attn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (iou_token): Embedding(1, 256)\n",
       "    (mask_tokens): Embedding(4, 256)\n",
       "    (output_upscaling): Sequential(\n",
       "      (0): ConvTranspose2d(256, 64, kernel_size=(2, 2), stride=(2, 2))\n",
       "      (1): LayerNorm2d()\n",
       "      (2): GELU(approximate='none')\n",
       "      (3): ConvTranspose2d(64, 32, kernel_size=(2, 2), stride=(2, 2))\n",
       "      (4): GELU(approximate='none')\n",
       "    )\n",
       "    (output_hypernetworks_mlps): ModuleList(\n",
       "      (0-3): 4 x MLP(\n",
       "        (layers): ModuleList(\n",
       "          (0-1): 2 x Linear(in_features=256, out_features=256, bias=True)\n",
       "          (2): Linear(in_features=256, out_features=32, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (iou_prediction_head): MLP(\n",
       "      (layers): ModuleList(\n",
       "        (0-1): 2 x Linear(in_features=256, out_features=256, bias=True)\n",
       "        (2): Linear(in_features=256, out_features=4, bias=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = sam_model_registry[MODEL_TYPE](checkpoint=CHECKPOINT_PATH)\n",
    "model.to(device)\n",
    "model.eval()  # Set model to evaluation mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "aad7f1ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to save masks\n",
    "def save_masks_to_disk():\n",
    "    # Define base directories\n",
    "    output_dir = \"exported_masks\"\n",
    "    images_dir = os.path.join(output_dir, \"images\")\n",
    "    masks_dir = os.path.join(output_dir, \"masks\")\n",
    "    os.makedirs(images_dir, exist_ok=True)\n",
    "    os.makedirs(masks_dir, exist_ok=True)\n",
    "\n",
    "    # Save the original image\n",
    "    image_output_path = os.path.join(images_dir, \"image.jpg\")\n",
    "    cv2.imwrite(image_output_path, map_image)\n",
    "\n",
    "    # Debug: Check if any masks are stored\n",
    "    if not st.session_state[\"masks_list\"]:\n",
    "        st.error(\"No masks to save. Please annotate the image before exporting.\")\n",
    "        return\n",
    "\n",
    "    # Initialize an empty mask for the entire image\n",
    "    height, width = map_image.shape[:2]\n",
    "    combined_mask = np.zeros((height, width), dtype=np.uint8)\n",
    "\n",
    "    # Define label mapping starting from 1\n",
    "    label_mapping = {label: idx+1 for idx, label in enumerate(labels)}\n",
    "    st.write(f\"Label mapping: {label_mapping}\")\n",
    "\n",
    "    # Iterate over masks and combine them\n",
    "    for idx, mask_info in enumerate(st.session_state[\"masks_list\"]):\n",
    "        mask = mask_info[\"mask\"]\n",
    "        label = mask_info[\"label\"]\n",
    "        class_id = label_mapping[label]\n",
    "\n",
    "        # Debug: Check mask content\n",
    "        mask_sum = np.sum(mask)\n",
    "        st.write(f\"Mask {idx} for label '{label}' has sum: {mask_sum}\")\n",
    "\n",
    "        # Update combined mask with the class ID\n",
    "        combined_mask[mask > 0] = class_id\n",
    "\n",
    "    # Save the combined mask (for model training)\n",
    "    mask_output_path = os.path.join(masks_dir, \"mask.png\")\n",
    "    cv2.imwrite(mask_output_path, combined_mask)\n",
    "\n",
    "    # Save a scaled version of the combined mask for visualization\n",
    "    max_class_id = max(label_mapping.values())\n",
    "    scaling_factor = 255 // max_class_id\n",
    "    scaled_mask = (combined_mask * scaling_factor).astype(np.uint8)\n",
    "    scaled_mask_output_path = os.path.join(masks_dir, \"mask_visualization.png\")\n",
    "    cv2.imwrite(scaled_mask_output_path, scaled_mask)\n",
    "\n",
    "    # Apply a color map for better visualization\n",
    "    color_mask = cv2.applyColorMap(scaled_mask, cv2.COLORMAP_JET)\n",
    "    color_mask_output_path = os.path.join(masks_dir, \"mask_color.png\")\n",
    "    cv2.imwrite(color_mask_output_path, color_mask)\n",
    "\n",
    "    # Optionally, save the annotated image\n",
    "    annotated_image_path = os.path.join(output_dir, \"annotated_image.jpg\")\n",
    "    cv2.imwrite(annotated_image_path, st.session_state[\"annotated_image\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e59724e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load map image and resize based on scaling\n",
    "map_image_path = \"datasets/aalesund/1504200/200.jpg\"\n",
    "map_image = cv2.imread(map_image_path)\n",
    "scale_percent = 10  # Adjust this value to change image size\n",
    "width = int(map_image.shape[1] * scale_percent / 100)\n",
    "height = int(map_image.shape[0] * scale_percent / 100)\n",
    "map_image = cv2.resize(map_image, (width, height), interpolation=cv2.INTER_AREA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9612adf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-18 08:11:14.524 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-11-18 08:11:14.528 WARNING streamlit.runtime.state.session_state_proxy: Session state does not function when running a script without `streamlit run`\n",
      "2024-11-18 08:11:14.529 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-11-18 08:11:14.530 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-11-18 08:11:14.538 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-11-18 08:11:14.540 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-11-18 08:11:14.540 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
     ]
    }
   ],
   "source": [
    "# Initialize session state for masks and annotated image if not set\n",
    "if \"masks_list\" not in st.session_state:\n",
    "    st.session_state[\"masks_list\"] = []\n",
    "if \"annotated_image\" not in st.session_state:\n",
    "    st.session_state[\"annotated_image\"] = map_image.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "248f0357",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-18 08:11:14.574 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-11-18 08:11:14.576 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-11-18 08:11:14.578 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-11-18 08:11:14.579 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-11-18 08:11:14.580 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-11-18 08:11:14.641 \n",
      "  \u001b[33m\u001b[1mWarning:\u001b[0m to view this Streamlit app on a browser, run it with the following\n",
      "  command:\n",
      "\n",
      "    streamlit run /usr/local/lib/python3.10/dist-packages/ipykernel_launcher.py [ARGUMENTS]\n",
      "2024-11-18 08:11:14.643 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
     ]
    }
   ],
   "source": [
    "# Add label selection in the sidebar\n",
    "labels = [\"Residential Area\", \"Forest\", \"Shooting Range\"]\n",
    "selected_label = st.sidebar.selectbox(\"Select Label for Next Mask\", labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d07b2f14",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-18 08:11:14.694 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-11-18 08:11:14.699 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-11-18 08:11:14.702 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-11-18 08:11:14.704 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-11-18 08:11:14.706 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
     ]
    }
   ],
   "source": [
    "# Button to reset masks\n",
    "if st.button(\"Reset Masks\"):\n",
    "    st.session_state[\"masks_list\"].clear()  # Remove all masks\n",
    "    st.session_state[\"annotated_image\"] = map_image.copy()  # Reset annotated image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2eb7ddae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-18 08:11:14.772 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-11-18 08:11:14.774 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-11-18 08:11:14.775 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-11-18 08:11:14.777 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-11-18 08:11:14.778 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
     ]
    }
   ],
   "source": [
    "# Button to export masks\n",
    "if st.button(\"Export Masks\"):\n",
    "    save_masks_to_disk()\n",
    "    st.success(\"Masks have been exported successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "60e9ee34",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-18 08:11:14.938 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-11-18 08:11:14.941 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-11-18 08:11:14.942 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-11-18 08:11:14.943 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-11-18 08:11:14.943 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-11-18 08:11:14.944 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-11-18 08:11:14.965 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-11-18 08:11:14.967 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
     ]
    }
   ],
   "source": [
    "# Display the image on canvas if loaded\n",
    "if map_image is not None:\n",
    "    # Convert map_image to PIL format for st_canvas\n",
    "    pil_image = Image.fromarray(cv2.cvtColor(map_image, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "    # Display the image with a canvas to capture click coordinates\n",
    "    canvas_result = st_canvas(\n",
    "        fill_color=\"rgba(255, 165, 0, 0.3)\",\n",
    "        stroke_width=3,\n",
    "        stroke_color=\"#000\",\n",
    "        background_image=pil_image,\n",
    "        update_streamlit=True,\n",
    "        height=pil_image.height,\n",
    "        width=pil_image.width,\n",
    "        drawing_mode=\"point\",\n",
    "        key=\"canvas\"\n",
    "    )\n",
    "\n",
    "    # Check if a point was clicked\n",
    "    if canvas_result.json_data and len(canvas_result.json_data[\"objects\"]) > 0:\n",
    "        # Get the last clicked point\n",
    "        x_coord = int(canvas_result.json_data[\"objects\"][-1][\"left\"])\n",
    "        y_coord = int(canvas_result.json_data[\"objects\"][-1][\"top\"])\n",
    "        st.write(f\"Clicked coordinates: ({x_coord}, {y_coord})\")\n",
    "\n",
    "        # Define input point for SAM\n",
    "        input_point = np.array([[x_coord, y_coord]])\n",
    "        input_label = np.array([1])  # SAM expects a binary label; 1 means foreground\n",
    "\n",
    "        # Use SamPredictor to set the image and predict the mask\n",
    "        predictor = SamPredictor(model)\n",
    "        predictor.set_image(map_image)\n",
    "\n",
    "        # Generate the mask from SAM with multimask_output argument\n",
    "        with torch.no_grad():\n",
    "            masks, scores, logits = predictor.predict(\n",
    "                point_coords=input_point,\n",
    "                point_labels=input_label,\n",
    "                multimask_output=False\n",
    "            )\n",
    "\n",
    "        # masks is a NumPy array of shape [num_masks, mask_height, mask_width]\n",
    "        # Resize mask to original image size\n",
    "        original_h, original_w = map_image.shape[:2]\n",
    "        mask = masks[0]  # Take the first mask, shape: (mask_height, mask_width)\n",
    "\n",
    "        # Resize mask using cv2\n",
    "        mask_resized = cv2.resize(mask.astype(np.float32), (original_w, original_h), interpolation=cv2.INTER_NEAREST)\n",
    "        # Binarize the resized mask\n",
    "        mask_resized = (mask_resized > 0).astype(np.uint8)\n",
    "\n",
    "        # Convert mask to uint8\n",
    "        mask_uint8 = (mask_resized * 255).astype(np.uint8)\n",
    "        mask_colored = cv2.applyColorMap(mask_uint8, cv2.COLORMAP_JET)\n",
    "\n",
    "        # Apply mask only on masked area\n",
    "        mask_overlay = st.session_state[\"annotated_image\"].copy()\n",
    "        # Create a boolean mask\n",
    "        mask_bool = mask_resized.astype(bool)\n",
    "\n",
    "        # Apply the overlay\n",
    "        mask_overlay[mask_bool] = cv2.addWeighted(\n",
    "            mask_overlay, 0.6, mask_colored, 0.4, 0\n",
    "        )[mask_bool]\n",
    "\n",
    "        # Update the annotated image with overlay applied only on masked area\n",
    "        st.session_state[\"annotated_image\"] = mask_overlay\n",
    "\n",
    "        # Store the mask with its label\n",
    "        st.session_state[\"masks_list\"].append({\n",
    "            \"mask\": mask_resized,\n",
    "            \"label\": selected_label\n",
    "        })\n",
    "\n",
    "    # Display the updated annotated image\n",
    "    st.image(st.session_state[\"annotated_image\"], channels=\"BGR\")\n",
    "else:\n",
    "    st.error(\"Could not load the image. Please check the file path.\")"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
