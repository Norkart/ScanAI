{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import base64\n",
    "from pdf2image import convert_from_path\n",
    "from openai import AzureOpenAI\n",
    "from PIL import Image\n",
    "import io\n",
    "import fitz \n",
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_base = \"\"\n",
    "api_key= \"\"\n",
    "api_version = \"2024-08-01-preview\"\n",
    "api_base = \"\"  # Base URL\n",
    "deployment_name = \"gpt-4o\"  # Deployment name from your endpoint\n",
    "\n",
    "# Initialize the AzureOpenAI client\n",
    "client = AzureOpenAI(\n",
    "    api_key=api_key,\n",
    "    api_version=api_version,\n",
    "    base_url=f\"{api_base}/openai/deployments/{deployment_name}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_image_from_pdf_base64(pdf_path, page_number=0, image_index=0):\n",
    "    \"\"\"\n",
    "    Extract an image from a specified page in a PDF and return it as a Base64-encoded string.\n",
    "    \n",
    "    Args:\n",
    "        pdf_path (str): Path to the PDF file.\n",
    "        page_number (int): Page number (0-indexed) to extract the image from.\n",
    "        image_index (int): Index of the image on the page (default is the first image).\n",
    "        \n",
    "    Returns:\n",
    "        str: Base64-encoded string of the extracted image, or None if no image is found.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        print(f\"Opening PDF: {pdf_path}\")\n",
    "        pdf_document = fitz.open(pdf_path)\n",
    "        print(f\"PDF successfully opened. Number of pages: {len(pdf_document)}\")\n",
    "\n",
    "        if page_number >= len(pdf_document):\n",
    "            print(f\"Error: Page number {page_number} is out of range. Total pages: {len(pdf_document)}\")\n",
    "            return None\n",
    "\n",
    "        print(f\"Loading page {page_number + 1}\")\n",
    "        page = pdf_document.load_page(page_number)\n",
    "        images = page.get_images(full=True)\n",
    "        print(f\"Number of images found on page {page_number + 1}: {len(images)}\")\n",
    "\n",
    "        if not images or image_index >= len(images):\n",
    "            print(f\"No image found on page {page_number + 1} at index {image_index}.\")\n",
    "            return None\n",
    "\n",
    "        print(f\"Extracting image at index {image_index} on page {page_number + 1}\")\n",
    "        xref = images[image_index][0]  # XREF of the image\n",
    "        base_image = pdf_document.extract_image(xref)\n",
    "        image_bytes = base_image[\"image\"]\n",
    "        print(f\"Image extracted successfully. Image size: {len(image_bytes)} bytes\")\n",
    "\n",
    "        print(f\"Decoding image bytes into NumPy array\")\n",
    "        image = cv2.imdecode(np.frombuffer(image_bytes, np.uint8), cv2.IMREAD_COLOR)\n",
    "\n",
    "        if image is None:\n",
    "            print(f\"Error: OpenCV failed to decode the image.\")\n",
    "            return None\n",
    "\n",
    "        print(f\"Image decoded successfully. Encoding to Base64.\")\n",
    "        pil_image = Image.fromarray(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "        img_byte_arr = io.BytesIO()\n",
    "        pil_image.save(img_byte_arr, format=\"JPEG\")\n",
    "        img_byte_arr.seek(0)\n",
    "        base64_image = base64.b64encode(img_byte_arr.read()).decode(\"utf-8\")\n",
    "        return base64_image\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        return None\n",
    "\n",
    "    finally:\n",
    "        if 'pdf_document' in locals():\n",
    "            pdf_document.close()\n",
    "            print(f\"PDF document closed.\")\n",
    "\n",
    "\n",
    "def numpy_to_binary_stream(image_array):\n",
    "    \"\"\"\n",
    "    Converts a NumPy image array to a binary stream.\n",
    "    Args:\n",
    "        image_array (np.ndarray): Image in NumPy array format.\n",
    "    Returns:\n",
    "        io.BytesIO: Binary stream of the image in JPEG format.\n",
    "    \"\"\"\n",
    "    pil_image = Image.fromarray(image_array)\n",
    "    binary_stream = io.BytesIO()\n",
    "    pil_image.save(binary_stream, format=\"JPEG\")\n",
    "    binary_stream.seek(0)  # Move to the start of the stream\n",
    "    return binary_stream\n",
    "\n",
    "# Convert a local image to Base64 (for the second image)\n",
    "def image_to_base64(image_path, percentage=100):\n",
    "    \"\"\"\n",
    "    Resize an image by a percentage and convert it to Base64.\n",
    "\n",
    "    Args:\n",
    "        image_path (str): Path to the image file.\n",
    "        percentage (int): Resize percentage (default is 100, no resizing).\n",
    "\n",
    "    Returns:\n",
    "        str: Base64-encoded string of the resized image.\n",
    "    \"\"\"\n",
    "    with Image.open(image_path) as img:\n",
    "        # Calculate new dimensions based on percentage\n",
    "        if percentage != 100:\n",
    "            width, height = img.size\n",
    "            new_width = int(width * (percentage / 100))\n",
    "            new_height = int(height * (percentage / 100))\n",
    "            img = img.resize((new_width, new_height), Image.Resampling.LANCZOS)\n",
    "        \n",
    "        # Save the resized image to a BytesIO buffer\n",
    "        img_byte_arr = io.BytesIO()\n",
    "        img.save(img_byte_arr, format='JPEG')\n",
    "        img_byte_arr.seek(0)  # Rewind the buffer\n",
    "        \n",
    "        # Convert to Base64\n",
    "        base64_image = base64.b64encode(img_byte_arr.read()).decode(\"utf-8\")\n",
    "    return base64_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = extract_image_from_pdf_base64(\"dataset/aalesund/FOKUS/1504200/200_tegnforklaring.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the chat completion request with the Base64 encoded images\n",
    "response = client.chat.completions.create(\n",
    "    model=deployment_name,\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": [\n",
    "            {\"type\": \"text\", \"text\": \"Write the areas and their corresponding colors. Be accurate when identifying which color belongs to each area name.\"},\n",
    "            {\"type\": \"image_url\", \"image_url\": {\"url\": f\"data:image/jpeg;base64,{image}\"}},\n",
    "        ]}\n",
    "    ],\n",
    "    max_tokens=4096\n",
    ")\n",
    "\n",
    "# Extract the message content\n",
    "message_content = response.choices[0].message.content\n",
    "\n",
    "# Print only the message content\n",
    "print(message_content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
