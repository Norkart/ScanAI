{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import base64\n",
    "from pdf2image import convert_from_path\n",
    "from openai import AzureOpenAI\n",
    "from PIL import Image, ImageOps\n",
    "import io\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add api key, api version, api base url, and deployment name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key= \"\"\n",
    "api_version = \"\"\n",
    "api_base = \"\" \n",
    "deployment_name = \"\"  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize the AzureOpenAI client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = AzureOpenAI(\n",
    "    api_key=api_key,\n",
    "    api_version=api_version,\n",
    "    base_url=f\"{api_base}/openai/deployments/{deployment_name}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Helper functions for converting pdfs to jpg and images to base 64."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pdf_to_base64(pdf_path):\n",
    "    images = convert_from_path(pdf_path, first_page=1, last_page=1)\n",
    "    image = images[0]  \n",
    "    \n",
    "    img_byte_arr = io.BytesIO()\n",
    "    image.save(img_byte_arr, format='JPEG')\n",
    "    img_byte_arr.seek(0)  \n",
    "\n",
    "    base64_image = base64.b64encode(img_byte_arr.read()).decode('utf-8')\n",
    "    return base64_image\n",
    "\n",
    "def jpg_to_base64(image_path, percentage=100, target_size=None, normalize=False):\n",
    "    \"\"\"\n",
    "    Preprocess an image (resize, normalize, and pad if needed) and convert it to Base64.\n",
    "\n",
    "    Args:\n",
    "        image_path (str): Path to the image file.\n",
    "        percentage (int): Resize percentage (default is 100, no resizing).\n",
    "        target_size (tuple): Optional target size (width, height) for resizing (default is None).\n",
    "        normalize (bool): Whether to normalize pixel values to [0, 1] (default is False).\n",
    "\n",
    "    Returns:\n",
    "        str: Base64-encoded string of the preprocessed image.\n",
    "    \"\"\"\n",
    "    with Image.open(image_path) as img:\n",
    "        img = img.convert(\"RGB\")\n",
    "\n",
    "        if target_size:\n",
    "            img = ImageOps.fit(img, target_size, method=Image.Resampling.LANCZOS, centering=(0.5, 0.5))\n",
    "        elif percentage != 100:\n",
    "            width, height = img.size\n",
    "            new_width = int(width * (percentage / 100))\n",
    "            new_height = int(height * (percentage / 100))\n",
    "            img = img.resize((new_width, new_height), Image.Resampling.LANCZOS)\n",
    "\n",
    "        if normalize:\n",
    "            img_array = np.array(img) / 255.0\n",
    "            img = Image.fromarray((img_array * 255).astype(np.uint8)) \n",
    "\n",
    "        img_byte_arr = io.BytesIO()\n",
    "        img.save(img_byte_arr, format='JPEG', quality=85)  \n",
    "        img_byte_arr.seek(0) \n",
    "\n",
    "        base64_image = base64.b64encode(img_byte_arr.read()).decode(\"utf-8\")\n",
    "    return base64_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initiate images, either jpg or pdf."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_image = jpg_to_base64(\"200.jpg\")\n",
    "\n",
    "map_explanation = pdf_to_base64(\"200_tegnforklaring.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Experiment with different prompts, and AI contexts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "context1 = \"\"\"\n",
    "You are a highly knowledgeable and precise expert in map analysis, specializing in identifying and extracting regions, features, and relevant details from maps. Your expertise includes understanding color-coded areas, boundaries, and labels, as well as accurately interpreting legends and visual information. Analyze the provided map image in detail, leveraging your advanced skills to identify all distinct regions based on the map's color scheme and boundaries.\n",
    "\n",
    "1. Carefully examine the entire map, ensuring no region is overlooked, including small, irregular, or partially obscured areas.\n",
    "2. Match the identified regions to their corresponding descriptions in the map's legend, providing an exact match for each color or feature.\n",
    "3. For each region, provide:\n",
    "   - Its bounding box coordinates (x_min, y_min, x_max, y_max) based on the map's resolution.\n",
    "   - The color or pattern associated with the region.\n",
    "   - Any text or labels present within the region.\n",
    "4. Consider subtle variations in colors or patterns and include all distinguishable areas, regardless of size or prominence.\n",
    "5. If the map contains overlapping or adjacent regions, clearly delineate them and avoid duplication.\n",
    "6. Take your time to ensure precision and accuracy in your analysis, ensuring no relevant detail is missed.\n",
    "\n",
    "Present your findings systematically, making it easy to parse and interpret programmatically or manually. Use structured formats where appropriate to ensure clarity and completeness.\n",
    "\"\"\"\n",
    "\n",
    "context2 = \"\"\"\n",
    "You are a highly skilled expert in reading and interpreting map explanations, including legends, labels, and associated color codes. Your task is to thoroughly analyze the provided map's explanation (legend) to identify the exact names of all areas and their corresponding colors. Leverage your expertise to ensure precision and accuracy in extracting this information.\n",
    "\n",
    "1. Carefully read the map explanation and interpret all details, including subtle variations in color shades or patterns.\n",
    "2. For each area listed in the explanation, provide:\n",
    "   - The exact name of the area as stated in the legend.\n",
    "   - The precise color code, shade, or pattern associated with the area.\n",
    "3. If the explanation includes unique patterns (e.g., striped or dotted regions), describe them clearly and associate them with their respective areas.\n",
    "4. Focus on clarity and avoid ambiguities; ensure each area name and its associated color are explicitly matched.\n",
    "5. Take your time to cross-check the information to ensure no area or color is omitted, regardless of prominence.\n",
    "\n",
    "Present your results in a structured and easy-to-interpret format, ensuring that each area name is clearly associated with its exact color or pattern as described in the map explanation.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "prompt1 = \"\"\"\n",
    "Analyze the provided image thoroughly. Focus specifically on identifying all orange areas in the image.\n",
    "Ensure that you capture every distinct orange region, including small, irregular, or partially obscured areas.\n",
    "Provide detailed coordinates for each orange area as bounding boxes (x_min, y_min, x_max, y_max).\n",
    "Take your time to carefully analyze and ensure no orange area is missed.\n",
    "\"\"\"\n",
    "\n",
    "prompt2 = \"\"\"\n",
    "Using the analysis results from the image, ensure each orange area's bounding box is clearly defined.\n",
    "If there are overlapping or adjacent areas, distinguish them clearly.\n",
    "List all orange areas systematically with their coordinates and size descriptions.\n",
    "Provide the results in a structured format that can be parsed programmatically.\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a chat completion request with the Base64 images and the desired prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.chat.completions.create(\n",
    "    model=deployment_name,\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": context1},\n",
    "        {\"role\": \"user\", \"content\": [\n",
    "            {\"type\": \"text\", \"text\": prompt1},\n",
    "            {\"type\": \"image_url\", \"image_url\": {\"url\": f\"data:image/jpeg;base64,{map_image}\"}},\n",
    "            {\"type\": \"image_url\", \"image_url\": {\"url\": f\"data:image/jpeg;base64,{map_explanation}\"}}\n",
    "        ]}\n",
    "    ],\n",
    "    max_tokens=4096\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
