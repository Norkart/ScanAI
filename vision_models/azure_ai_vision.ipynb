{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from azure.ai.vision.imageanalysis import ImageAnalysisClient\n",
    "from azure.ai.vision.imageanalysis.models import VisualFeatures\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "from pdf2image import convert_from_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Helper function for turning pdfs to jpgs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pdf_to_jpg(pdf_path, output_path=\"converted_image.jpg\"):\n",
    "    \"\"\"\n",
    "    Convert the first page of a PDF to a JPG image.\n",
    "\n",
    "    Args:\n",
    "        pdf_path (str): Path to the input PDF file.\n",
    "        output_path (str): Path to save the converted JPG image.\n",
    "\n",
    "    Returns:\n",
    "        str: Path to the saved JPG image.\n",
    "    \"\"\"\n",
    "    # Convert the first page of the PDF to an image\n",
    "    images = convert_from_path(pdf_path, first_page=1, last_page=1)\n",
    "    if images:\n",
    "        images[0].save(output_path, format=\"JPEG\")\n",
    "        return output_path\n",
    "    else:\n",
    "        raise ValueError(\"No pages found in the PDF file.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up the values for the endpoint and api key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    endpoint = \"\"\n",
    "    key = \"\"\n",
    "except KeyError:\n",
    "    print(\"Missing environment variable 'VISION_ENDPOINT' or 'VISION_KEY'\")\n",
    "    print(\"Set them before running this sample.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up an Image Analysis client."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = ImageAnalysisClient(\n",
    "    endpoint=endpoint,\n",
    "    credential=AzureKeyCredential(key)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initiate the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#image_path = \"200.jpg\"\n",
    "\n",
    "image_path = pdf_to_jpg(\"200_tegnforklaring.pdf\")\n",
    "\n",
    "with open(image_path, \"rb\") as f:\n",
    "    image_data = f.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the visual features you want to analyze."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visual_features =[\n",
    "    VisualFeatures.TAGS,\n",
    "    VisualFeatures.OBJECTS,\n",
    "    VisualFeatures.CAPTION,\n",
    "    VisualFeatures.DENSE_CAPTIONS,\n",
    "    VisualFeatures.READ,\n",
    "    VisualFeatures.SMART_CROPS,\n",
    "    VisualFeatures.PEOPLE,\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analyze the image using the analyze method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = client.analyze(\n",
    "    image_data=image_data,\n",
    "    visual_features=visual_features,\n",
    "    gender_neutral_caption=True, \n",
    "    language=\"en\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print all the analysis results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Image analysis results:\")\n",
    "\n",
    "if result.caption is not None:\n",
    "    print(\" Caption:\")\n",
    "    print(f\"   '{result.caption.text}', Confidence {result.caption.confidence:.4f}\")\n",
    "\n",
    "if result.dense_captions is not None:\n",
    "    print(\" Dense Captions:\")\n",
    "    for caption in result.dense_captions.list:\n",
    "        print(f\"   '{caption.text}', {caption.bounding_box}, Confidence: {caption.confidence:.4f}\")\n",
    "\n",
    "if result.read is not None:\n",
    "    print(\" Read:\")\n",
    "    for line in result.read.blocks[0].lines:\n",
    "        print(f\"   Line: '{line.text}', Bounding box {line.bounding_polygon}\")\n",
    "        for word in line.words:\n",
    "            print(f\"     Word: '{word.text}', Bounding polygon {word.bounding_polygon}, Confidence {word.confidence:.4f}\")\n",
    "\n",
    "if result.tags is not None:\n",
    "    print(\" Tags:\")\n",
    "    for tag in result.tags.list:\n",
    "        print(f\"   '{tag.name}', Confidence {tag.confidence:.4f}\")\n",
    "\n",
    "if result.objects is not None:\n",
    "    print(\" Objects:\")\n",
    "    for object in result.objects.list:\n",
    "        print(f\"   '{object.tags[0].name}', {object.bounding_box}, Confidence: {object.tags[0].confidence:.4f}\")\n",
    "\n",
    "if result.people is not None:\n",
    "    print(\" People:\")\n",
    "    for person in result.people.list:\n",
    "        print(f\"   {person.bounding_box}, Confidence {person.confidence:.4f}\")\n",
    "\n",
    "if result.smart_crops is not None:\n",
    "    print(\" Smart Cropping:\")\n",
    "    for smart_crop in result.smart_crops.list:\n",
    "        print(f\"   Aspect ratio {smart_crop.aspect_ratio}: Smart crop {smart_crop.bounding_box}\")\n",
    "\n",
    "print(f\" Image height: {result.metadata.height}\")\n",
    "print(f\" Image width: {result.metadata.width}\")\n",
    "print(f\" Model version: {result.model_version}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
