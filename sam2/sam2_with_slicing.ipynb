{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importer dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import os\n",
    "from sam2.build_sam import build_sam2\n",
    "from sam2.automatic_mask_generator import SAM2AutomaticMaskGenerator\n",
    "from hydra import initialize\n",
    "from hydra.core.global_hydra import GlobalHydra\n",
    "from supervision import Detections\n",
    "from supervision.draw.color import ColorPalette\n",
    "import supervision as sv\n",
    "import image_slicer\n",
    "from shapely.geometry import Polygon\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Configure PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use torch.no_grad() to disable gradient computations\n",
    "torch.autograd.set_grad_enabled(False)\n",
    "\n",
    "# Check if CUDA is available and set device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Enable benchmark mode in cudnn for performance\n",
    "torch.backends.cudnn.benchmark = True\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust_mask_coordinates(mask, x_offset, y_offset, image_shape):\n",
    "    \"\"\"\n",
    "    Adjusts the mask coordinates to the original image coordinates.\n",
    "\n",
    "    Args:\n",
    "        mask (numpy.ndarray): The binary mask.\n",
    "        x_offset (int): The x-coordinate offset of the tile.\n",
    "        y_offset (int): The y-coordinate offset of the tile.\n",
    "        image_shape (tuple): The shape of the original image.\n",
    "\n",
    "    Returns:\n",
    "        numpy.ndarray: The adjusted mask.\n",
    "    \"\"\"\n",
    "    full_mask = np.zeros(image_shape[:2], dtype=mask.dtype)\n",
    "    mask_height, mask_width = mask.shape\n",
    "    full_mask[y_offset:y_offset + mask_height, x_offset:x_offset + mask_width] = mask\n",
    "    return full_mask\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load and preprocess image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the image\n",
    "image_path = 'datasets/aalesund/1504201/201.jpg'\n",
    "image_bgr = cv2.imread(image_path)\n",
    "\n",
    "# Convert to RGB for processing\n",
    "image_rgb = cv2.cvtColor(image_bgr, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# Get image dimensions\n",
    "image_height, image_width = image_rgb.shape[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import and initialize SAM2 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UserWarning: \n",
      "The version_base parameter is not specified.\n",
      "Please specify a compatability version level, or None.\n",
      "Will assume defaults for version 1.1\n"
     ]
    }
   ],
   "source": [
    "# Paths to configuration and checkpoint files\n",
    "config_file_path = \"./sam2.1_hiera_l.yaml\"\n",
    "checkpoint_file_path = \"./sam2.1_hiera_large.pt\"\n",
    "\n",
    "# Verify file existence\n",
    "assert os.path.exists(config_file_path), f\"Config file not found at {config_file_path}\"\n",
    "assert os.path.exists(checkpoint_file_path), f\"Checkpoint file not found at {checkpoint_file_path}\"\n",
    "\n",
    "# Clear any existing Hydra instances\n",
    "GlobalHydra.instance().clear()\n",
    "\n",
    "# Initialize Hydra and build the model\n",
    "with initialize(config_path=\".\"):\n",
    "    sam2_model = build_sam2(config_file=config_file_path, ckpt_path=checkpoint_file_path).to(device)\n",
    "\n",
    "# Set model to evaluation mode\n",
    "sam2_model.eval()\n",
    "\n",
    "# Create the mask generator with optimized parameters\n",
    "mask_generator = SAM2AutomaticMaskGenerator(\n",
    "    model=sam2_model,\n",
    "    points_per_side=32,  # Adjusted for performance\n",
    "    pred_iou_thresh=0.8,\n",
    "    stability_score_thresh=0.9,\n",
    "    stability_score_offset=1.0,\n",
    "    mask_threshold=0.0,\n",
    "    box_nms_thresh=1.0,\n",
    "    crop_n_layers=0,\n",
    "    min_mask_region_area=0,\n",
    "    output_mode=\"binary_mask\",\n",
    "    use_m2m=True,\n",
    "    multimask_output=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create mask generator and generate masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "import image_slicer\n",
    "from PIL import Image\n",
    "\n",
    "# Choose the number of tiles\n",
    "num_tiles = 4  # Adjust to 2, 4, 8, etc.\n",
    "\n",
    "# Slice the image\n",
    "tiles = image_slicer.slice(image_path, num_tiles, save=False)\n",
    "\n",
    "# Map tile numbers to their positions\n",
    "tile_positions = {}\n",
    "tile_width = tiles[0].image.width\n",
    "tile_height = tiles[0].image.height\n",
    "\n",
    "for tile in tiles:\n",
    "    # tile.number ranges from 1 to num_tiles\n",
    "    col_index = (tile.column - 1)\n",
    "    row_index = (tile.row - 1)\n",
    "    x_offset = col_index * tile_width\n",
    "    y_offset = row_index * tile_height\n",
    "    tile_positions[tile.number] = (x_offset, y_offset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[98], line 14\u001b[0m\n\u001b[1;32m     11\u001b[0m tile_image_rgb \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mcvtColor(tile_image, cv2\u001b[38;5;241m.\u001b[39mCOLOR_RGB2BGR)\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# Generate masks for the tile\u001b[39;00m\n\u001b[0;32m---> 14\u001b[0m tile_masks \u001b[38;5;241m=\u001b[39m \u001b[43mmask_generator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtile_image_rgb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# Get x and y offsets\u001b[39;00m\n\u001b[1;32m     17\u001b[0m x_offset, y_offset \u001b[38;5;241m=\u001b[39m tile_positions[tile\u001b[38;5;241m.\u001b[39mnumber]\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/utils/_contextlib.py:116\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 116\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sam2/automatic_mask_generator.py:196\u001b[0m, in \u001b[0;36mSAM2AutomaticMaskGenerator.generate\u001b[0;34m(self, image)\u001b[0m\n\u001b[1;32m    171\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    172\u001b[0m \u001b[38;5;124;03mGenerates masks for the given image.\u001b[39;00m\n\u001b[1;32m    173\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    192\u001b[0m \u001b[38;5;124;03m         the mask, given in XYWH format.\u001b[39;00m\n\u001b[1;32m    193\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    195\u001b[0m \u001b[38;5;66;03m# Generate masks\u001b[39;00m\n\u001b[0;32m--> 196\u001b[0m mask_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate_masks\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    198\u001b[0m \u001b[38;5;66;03m# Encode masks\u001b[39;00m\n\u001b[1;32m    199\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcoco_rle\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sam2/automatic_mask_generator.py:233\u001b[0m, in \u001b[0;36mSAM2AutomaticMaskGenerator._generate_masks\u001b[0;34m(self, image)\u001b[0m\n\u001b[1;32m    231\u001b[0m data \u001b[38;5;241m=\u001b[39m MaskData()\n\u001b[1;32m    232\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m crop_box, layer_idx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(crop_boxes, layer_idxs):\n\u001b[0;32m--> 233\u001b[0m     crop_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_process_crop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcrop_box\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlayer_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morig_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    234\u001b[0m     data\u001b[38;5;241m.\u001b[39mcat(crop_data)\n\u001b[1;32m    236\u001b[0m \u001b[38;5;66;03m# Remove duplicate masks between crops\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sam2/automatic_mask_generator.py:271\u001b[0m, in \u001b[0;36mSAM2AutomaticMaskGenerator._process_crop\u001b[0;34m(self, image, crop_box, crop_layer_idx, orig_size)\u001b[0m\n\u001b[1;32m    269\u001b[0m data \u001b[38;5;241m=\u001b[39m MaskData()\n\u001b[1;32m    270\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m (points,) \u001b[38;5;129;01min\u001b[39;00m batch_iterator(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpoints_per_batch, points_for_image):\n\u001b[0;32m--> 271\u001b[0m     batch_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_process_batch\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpoints\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcropped_im_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcrop_box\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morig_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnormalize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[1;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    274\u001b[0m     data\u001b[38;5;241m.\u001b[39mcat(batch_data)\n\u001b[1;32m    275\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m batch_data\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sam2/automatic_mask_generator.py:359\u001b[0m, in \u001b[0;36mSAM2AutomaticMaskGenerator._process_batch\u001b[0;34m(self, points, im_size, crop_box, orig_size, normalize)\u001b[0m\n\u001b[1;32m    357\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpred_iou_thresh \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0.0\u001b[39m:\n\u001b[1;32m    358\u001b[0m     keep_mask \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miou_preds\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpred_iou_thresh\n\u001b[0;32m--> 359\u001b[0m     \u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfilter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeep_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    361\u001b[0m data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstability_score\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m calculate_stability_score(\n\u001b[1;32m    362\u001b[0m     data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmasks\u001b[39m\u001b[38;5;124m\"\u001b[39m], \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmask_threshold, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstability_score_offset\n\u001b[1;32m    363\u001b[0m )\n\u001b[1;32m    364\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstability_score_thresh \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0.0\u001b[39m:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sam2/utils/amg.py:51\u001b[0m, in \u001b[0;36mMaskData.filter\u001b[0;34m(self, keep)\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stats[k] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(v, torch\u001b[38;5;241m.\u001b[39mTensor):\n\u001b[0;32m---> 51\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stats[k] \u001b[38;5;241m=\u001b[39m v[torch\u001b[38;5;241m.\u001b[39mas_tensor(keep, device\u001b[38;5;241m=\u001b[39mv\u001b[38;5;241m.\u001b[39mdevice)]\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(v, np\u001b[38;5;241m.\u001b[39mndarray):\n\u001b[1;32m     53\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stats[k] \u001b[38;5;241m=\u001b[39m v[keep\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "all_masks = []\n",
    "mask_id_counter = 0  # Unique identifier for each mask\n",
    "\n",
    "# Disable gradients and process each tile\n",
    "with torch.no_grad():\n",
    "    for tile in tiles:\n",
    "        tile_image_pil = tile.image.convert('RGB')  # Ensure image is in RGB\n",
    "        tile_image = np.array(tile_image_pil)\n",
    "        \n",
    "        # Convert to RGB format expected by the model\n",
    "        tile_image_rgb = cv2.cvtColor(tile_image, cv2.COLOR_RGB2BGR)\n",
    "        \n",
    "        # Generate masks for the tile\n",
    "        tile_masks = mask_generator.generate(tile_image_rgb)\n",
    "        \n",
    "        # Get x and y offsets\n",
    "        x_offset, y_offset = tile_positions[tile.number]\n",
    "        \n",
    "        # Adjust mask coordinates to the original image\n",
    "        for mask in tile_masks:\n",
    "            # Adjust the segmentation mask\n",
    "            full_mask = adjust_mask_coordinates(mask['segmentation'], x_offset, y_offset, image_rgb.shape)\n",
    "            mask['segmentation'] = full_mask\n",
    "            \n",
    "            # Assign a unique ID to each mask\n",
    "            mask['mask_id'] = mask_id_counter\n",
    "            mask_id_counter += 1\n",
    "            \n",
    "            all_masks.append(mask)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Post-process masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign random colors to each mask for visualization\n",
    "color_palette = ColorPalette()\n",
    "\n",
    "# Create detections from masks\n",
    "detections = Detections(\n",
    "    xyxy=[],\n",
    "    mask=np.array([mask['segmentation'] for mask in all_masks])\n",
    ")\n",
    "\n",
    "# Annotate the image\n",
    "mask_annotator = sv.MaskAnnotator(color=color_palette, opacity=0.6)\n",
    "annotated_image = mask_annotator.annotate(\n",
    "    scene=image_bgr.copy(),\n",
    "    detections=detections\n",
    ")\n",
    "\n",
    "# Display the annotated image\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.imshow(cv2.cvtColor(annotated_image, cv2.COLOR_BGR2RGB))\n",
    "plt.title(\"Annotated Image with Masks\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Annotate image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "polygons_list = []\n",
    "\n",
    "# Loop over each mask\n",
    "for mask in all_masks:\n",
    "    # Find contours in the mask\n",
    "    contours, _ = cv2.findContours(mask['segmentation'].astype(np.uint8), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    # Process each contour\n",
    "    for contour in contours:\n",
    "        if contour.shape[0] >= 3:\n",
    "            # Simplify the contour\n",
    "            epsilon = 0.01 * cv2.arcLength(contour, True)\n",
    "            approx = cv2.approxPolyDP(contour, epsilon, True)\n",
    "            # Convert to Polygon\n",
    "            poly = Polygon(approx.reshape(-1, 2))\n",
    "            if poly.is_valid and poly.area > 0:\n",
    "                polygons_list.append({\n",
    "                    'polygon': poly,\n",
    "                    'mask_id': mask['mask_id']\n",
    "                })\n",
    "\n",
    "# Prepare image for drawing polygons\n",
    "image_with_polygons = image_bgr.copy()\n",
    "\n",
    "# Draw polygons on the image\n",
    "for item in polygons_list:\n",
    "    poly = item['polygon']\n",
    "    color = color_palette.by_idx(item['mask_id'])\n",
    "    coords = np.array(list(poly.exterior.coords)).astype(np.int32)\n",
    "    cv2.polylines(image_with_polygons, [coords], isClosed=True, color=color.as_bgr(), thickness=2)\n",
    "\n",
    "# Display the image with vectorized polygons\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.imshow(cv2.cvtColor(image_with_polygons, cv2.COLOR_BGR2RGB))\n",
    "plt.title(\"Image with Vectorized Polygons\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert masks to polygons and display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
