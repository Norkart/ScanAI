{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import os\n",
    "import hydra\n",
    "from hydra import initialize_config_module, initialize, compose\n",
    "from hydra.core.global_hydra import GlobalHydra\n",
    "import sys\n",
    "from samgeo import SamGeo2, SamGeo\n",
    "import cv2\n",
    "import rasterio\n",
    "!pip install pymupdf\n",
    "import fitz \n",
    "\n",
    "\n",
    "# use bfloat16 for the entire notebook\n",
    "torch.autocast(device_type=\"cuda\", dtype=torch.float16).__enter__()\n",
    " \n",
    "if torch.cuda.get_device_properties(0).major >= 8:\n",
    "    # turn on tfloat32 for Ampere GPUs (https://pytorch.org/docs/stable/notes/cuda.html#tensorfloat-32-tf32-on-ampere-devices)\n",
    "    torch.backends.cuda.matmul.allow_tf32 = True\n",
    "    torch.backends.cudnn.allow_tf32 = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_image_from_pdf(pdf_path, page_number=0, image_index=0):\n",
    "    \"\"\"\n",
    "    Extract an image from a specified page in a PDF.\n",
    "    \n",
    "    Args:\n",
    "        pdf_path (str): Path to the PDF file.\n",
    "        page_number (int): Page number (0-indexed) to extract the image from.\n",
    "        image_index (int): Index of the image on the page (default is the first image).\n",
    "        \n",
    "    Returns:\n",
    "        np.ndarray: Extracted image in RGB format, or None if no image is found.\n",
    "    \"\"\"\n",
    "    # Open the PDF\n",
    "    pdf_document = fitz.open(pdf_path)\n",
    "    page = pdf_document.load_page(page_number)  # Load the specified page\n",
    "    images = page.get_images(full=True)  # Get all images on the page\n",
    "\n",
    "    if not images or image_index >= len(images):\n",
    "        print(f\"No image found on page {page_number + 1} at index {image_index}.\")\n",
    "        return None\n",
    "\n",
    "    # Extract the specified image\n",
    "    xref = images[image_index][0]  # XREF of the image\n",
    "    base_image = pdf_document.extract_image(xref)\n",
    "    image_bytes = base_image[\"image\"]\n",
    "\n",
    "    # Convert to a NumPy array\n",
    "    image = cv2.imdecode(np.frombuffer(image_bytes, np.uint8), cv2.IMREAD_COLOR)\n",
    "    pdf_document.close()\n",
    "    return cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# Load the image\n",
    "#image_bgr = cv2.imread('dataset/aalesund/FOKUS/1504200/200.jpg')\n",
    "#image_bgr = cv2.imread('dataset/aalesund/UTFORDRING/Monokrom/1504343A/343a.jpg')\n",
    "#image_bgr = cv2.imread('aalesund_fokus/213.jpg')\n",
    "#image_bgr = cv2.imread('dataset/molde/UTFORDRING/0577/0577_plankart.tif')\n",
    "\n",
    "image_rgb = extract_image_from_pdf('dataset/kristiansund/FOKUS/R-077/R-077 Plankart.pdf') \n",
    "image_bgr = cv2.cvtColor(image_rgb, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "#image_rgb = cv2.cvtColor(image_bgr, cv2.COLOR_BGR2RGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from hydra import initialize, compose\n",
    "from hydra.core.global_hydra import GlobalHydra\n",
    "from sam2.build_sam import build_sam2\n",
    "from sam2.automatic_mask_generator import SAM2AutomaticMaskGenerator\n",
    "\n",
    "# Move the model to the desired device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "mask_generator = SAM2AutomaticMaskGenerator.from_pretrained(\n",
    "    model_id=\"facebook/sam2-hiera-large\",\n",
    "    points_per_side=32,  # Define points per side\n",
    "    points_per_batch=16,  # Number of points per batch\n",
    "    pred_iou_thresh=0.75,  # Filter threshold for mask quality\n",
    "    stability_score_thresh=0.75,  # Filter threshold for stability score\n",
    "    stability_score_offset=1.0,\n",
    "    mask_threshold=0.0,\n",
    "    box_nms_thresh=0.5,           \n",
    "    crop_n_layers=1,\n",
    "    crop_nms_thresh=1,\n",
    "    crop_overlap_ratio=0.8,        \n",
    "    crop_n_points_downscale_factor=1,\n",
    "    point_grids=None,\n",
    "    min_mask_region_area=0,\n",
    "    output_mode=\"binary_mask\",\n",
    "    use_m2m=True,                  \n",
    "    multimask_output=False\n",
    ")\n",
    "\n",
    "print(\"Model and mask generator initialized successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sam_result = mask_generator.generate(image_rgb)\n",
    "#mask_generator.generate(image_rgb)\n",
    "#sam_result = mask_generator.masks\n",
    "print(len(sam_result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary modules\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "# Define function to check if one mask is completely inside another\n",
    "def is_mask_inside(outer_mask, inner_mask):\n",
    "    # Check if all True pixels in inner_mask are also True in outer_mask\n",
    "    return np.all(outer_mask[inner_mask > 0])\n",
    "\n",
    "# Define function to check if a mask is on a predominantly gray or black background\n",
    "def is_colorful_region(image, mask, saturation_threshold=20, brightness_threshold=50):\n",
    "    \"\"\"\n",
    "    Checks if the region within the mask is sufficiently colorful and bright.\n",
    "    Args:\n",
    "        image: Original image (in BGR format).\n",
    "        mask: Binary mask for the region of interest.\n",
    "        saturation_threshold: Minimum saturation required to consider a region colorful.\n",
    "        brightness_threshold: Minimum brightness required to consider a region bright.\n",
    "    Returns:\n",
    "        bool: True if the region is colorful and bright, False otherwise.\n",
    "    \"\"\"\n",
    "    # Ensure the mask is of type uint8 and has the same shape as the image's first two dimensions\n",
    "    if mask.ndim == 2:  # If mask is already 2D\n",
    "        mask = mask.astype(np.uint8)\n",
    "    else:\n",
    "        raise ValueError(\"The mask should be a 2D binary array.\")\n",
    "\n",
    "    # Resize the mask if it does not match the image dimensions\n",
    "    if mask.shape != image.shape[:2]:\n",
    "        mask = cv2.resize(mask, (image.shape[1], image.shape[0]), interpolation=cv2.INTER_NEAREST)\n",
    "\n",
    "    # Scale binary mask (0 or 1) to 0 or 255\n",
    "    mask = mask * 255\n",
    "\n",
    "    # Convert the image to HSV color space\n",
    "    hsv_image = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "    # Apply the mask to extract the region of interest\n",
    "    masked_hsv = cv2.bitwise_and(hsv_image, hsv_image, mask=mask)\n",
    "\n",
    "    # Extract the saturation (S) and value (V) channels\n",
    "    saturation = masked_hsv[..., 1]\n",
    "    brightness = masked_hsv[..., 2]\n",
    "\n",
    "    # Calculate the mean saturation and brightness within the mask\n",
    "    mean_saturation = cv2.mean(saturation, mask=mask)[0]\n",
    "    mean_brightness = cv2.mean(brightness, mask=mask)[0]\n",
    "\n",
    "    # Determine if the region is colorful and bright\n",
    "    return mean_saturation > saturation_threshold and mean_brightness > brightness_threshold\n",
    "\n",
    "\n",
    "\n",
    "# Step 1: Extract masks, compute area, and compute bounding boxes for sorting\n",
    "# Include the index to reference back to `sam_result`\n",
    "masks_with_areas_and_bboxes = []\n",
    "for i, mask in enumerate(sam_result):\n",
    "    segmentation = mask['segmentation']\n",
    "    if np.any(segmentation):\n",
    "        area = np.sum(segmentation)\n",
    "        # Compute bounding box\n",
    "        coords = np.argwhere(segmentation)\n",
    "        y_coords, x_coords = coords[:, 0], coords[:, 1]\n",
    "        min_x, max_x = x_coords.min(), x_coords.max()\n",
    "        min_y, max_y = y_coords.min(), y_coords.max()\n",
    "        bbox = (min_x, min_y, max_x, max_y)\n",
    "        masks_with_areas_and_bboxes.append((i, segmentation, area, bbox))\n",
    "\n",
    "# Sort masks by area (from largest to smallest)\n",
    "masks_with_areas_and_bboxes.sort(key=lambda x: x[2], reverse=True)  # (index, mask, area, bbox)\n",
    "\n",
    "# Set the threshold for the minimum number of contained masks required to remove a mask\n",
    "contained_mask_threshold = int(0.1 * len(masks_with_areas_and_bboxes))\n",
    "\n",
    "# Identify masks to remove\n",
    "indices_to_remove = set()\n",
    "\n",
    "# Loop through masks and remove larger masks that contain multiple smaller masks\n",
    "for i, (outer_idx, outer_mask, outer_area, outer_bbox) in enumerate(masks_with_areas_and_bboxes):\n",
    "    outer_min_x, outer_min_y, outer_max_x, outer_max_y = outer_bbox\n",
    "    contained_count = 0  # Counter for masks contained within the current outer mask\n",
    "\n",
    "    # Only consider smaller masks\n",
    "    for inner_idx, inner_mask, inner_area, inner_bbox in masks_with_areas_and_bboxes[i+1:]:\n",
    "        inner_min_x, inner_min_y, inner_max_x, inner_max_y = inner_bbox\n",
    "\n",
    "        # Check if inner bounding box is entirely within outer bounding box\n",
    "        if (inner_min_x >= outer_min_x and inner_max_x <= outer_max_x and\n",
    "            inner_min_y >= outer_min_y and inner_max_y <= outer_max_y):\n",
    "            # Now check if inner_mask is inside outer_mask\n",
    "            if is_mask_inside(outer_mask, inner_mask):\n",
    "                contained_count += 1  # Increment count for each contained mask\n",
    "\n",
    "    # Only mark the larger mask for removal if it contains at least `contained_mask_threshold` smaller masks\n",
    "    if contained_count >= contained_mask_threshold:\n",
    "        indices_to_remove.add(outer_idx)\n",
    "\n",
    "# Filter out the unwanted masks\n",
    "filtered_masks_with_areas_and_bboxes = [\n",
    "    (idx, mask, area, bbox)\n",
    "    for idx, mask, area, bbox in masks_with_areas_and_bboxes\n",
    "    if idx not in indices_to_remove\n",
    "]\n",
    "\n",
    "# Also remove any masks that cover the entire image (if any)\n",
    "image_area = image_bgr.shape[0] * image_bgr.shape[1]\n",
    "filtered_masks_with_areas_and_bboxes = [\n",
    "    (idx, mask, area, bbox)\n",
    "    for idx, mask, area, bbox in filtered_masks_with_areas_and_bboxes\n",
    "    if area < image_area\n",
    "]\n",
    "\n",
    "# Apply brightness filtering to remove masks with predominantly gray or black backgrounds\n",
    "filtered_masks_with_areas_and_bboxes = [\n",
    "    (idx, mask, area, bbox)\n",
    "    for idx, mask, area, bbox in filtered_masks_with_areas_and_bboxes\n",
    "    if is_colorful_region(image_bgr, mask, saturation_threshold=0, brightness_threshold=0)\n",
    "]\n",
    "\n",
    "# Create a filtered sam_result\n",
    "filtered_sam_result = [sam_result[idx] for idx, _, _, _ in filtered_masks_with_areas_and_bboxes]\n",
    "\n",
    "# Debug: Print the number of masks after filtering\n",
    "print(f\"Total masks after filtering: {len(filtered_sam_result)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from shapely.geometry import MultiPolygon, Polygon\n",
    "\n",
    "polygons_list = []\n",
    "\n",
    "# Prepare a copy of the original image for drawing polygons\n",
    "image_with_polygons = image_bgr.copy()\n",
    "\n",
    "# Image area\n",
    "image_area = image_bgr.shape[0] * image_bgr.shape[1]\n",
    "\n",
    "# List to store polygons with their area\n",
    "mask_polygons = []\n",
    "\n",
    "# Function to smooth contour using moving average\n",
    "def smooth_contour(contour, window_size=5):\n",
    "    # Ensure window_size is odd\n",
    "    if window_size % 2 == 0:\n",
    "        window_size += 1\n",
    "    half_window = window_size // 2\n",
    "\n",
    "    # Pad the contour to handle the circular nature\n",
    "    contour = np.concatenate((contour[-half_window:], contour, contour[:half_window]), axis=0)\n",
    "    \n",
    "    smoothed_contour = []\n",
    "    for i in range(half_window, len(contour) - half_window):\n",
    "        window_points = contour[i - half_window:i + half_window + 1]\n",
    "        mean_point = np.mean(window_points, axis=0)\n",
    "        smoothed_contour.append(mean_point)\n",
    "    smoothed_contour = np.array(smoothed_contour, dtype=np.int32)\n",
    "    return smoothed_contour\n",
    "\n",
    "# Loop over each mask in the filtered SAM result\n",
    "for idx, mask_dict in enumerate(filtered_sam_result):\n",
    "    mask = mask_dict['segmentation'].astype(np.uint8)  # Ensure mask is in uint8 format\n",
    "\n",
    "    # Find contours in the mask\n",
    "    contours, hierarchy = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
    "\n",
    "    # Skip if no contours are found\n",
    "    if not contours:\n",
    "        continue\n",
    "\n",
    "    # Process each contour\n",
    "    for contour in contours:\n",
    "        if contour.shape[0] < 5:\n",
    "            continue  # Need at least 5 points to smooth\n",
    "\n",
    "        # Reshape contour to 2D array\n",
    "        contour = contour.reshape(-1, 2)\n",
    "\n",
    "        # Smooth the contour using moving average\n",
    "        smoothed_contour = smooth_contour(contour, window_size=15)  # Adjust window_size as needed\n",
    "\n",
    "        if smoothed_contour.shape[0] >= 3:\n",
    "            polygon = Polygon(smoothed_contour)\n",
    "            # Ensure the polygon is valid\n",
    "            if not polygon.is_valid or polygon.area == 0:\n",
    "                # Try fixing invalid polygons\n",
    "                polygon = polygon.buffer(0)\n",
    "                if not polygon.is_valid or polygon.area == 0:\n",
    "                    continue  # Skip if still invalid\n",
    "            # Store the polygon along with its area and index\n",
    "            mask_polygons.append({'area': polygon.area, 'polygon': polygon, 'index': idx})\n",
    "\n",
    "# Introduce max_area_threshold to exclude overly large polygons\n",
    "max_area_threshold = 0.1 * image_area  # Exclude polygons covering more than 90% of the image\n",
    "\n",
    "# Filter out masks that are too large\n",
    "mask_polygons = [mp for mp in mask_polygons if mp['area'] < max_area_threshold]\n",
    "\n",
    "# Debug: Print the number of polygons after excluding large masks\n",
    "print(f\"Total polygons after excluding large masks: {len(mask_polygons)}\")\n",
    "\n",
    "# Now, filter out smaller polygons that are mostly within larger ones\n",
    "# Sort polygons by area in descending order\n",
    "mask_polygons.sort(key=lambda x: x['area'], reverse=True)\n",
    "\n",
    "# Initialize list to hold the final polygons\n",
    "filtered_polygons = []\n",
    "\n",
    "# Function to check if a polygon is mostly within existing polygons\n",
    "def is_polygon_mostly_within(poly, existing_polys, area_overlap_threshold=0.95):\n",
    "    for existing_poly in existing_polys:\n",
    "        intersection_area = poly.intersection(existing_poly).area\n",
    "        if poly.area == 0:\n",
    "            continue\n",
    "        overlap_ratio = intersection_area / poly.area\n",
    "        if overlap_ratio >= area_overlap_threshold:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "# Process each polygon\n",
    "for idx, poly_dict in enumerate(mask_polygons):\n",
    "    poly = poly_dict['polygon']\n",
    "    if not is_polygon_mostly_within(poly, [d['polygon'] for d in filtered_polygons], area_overlap_threshold=0.05):\n",
    "        filtered_polygons.append(poly_dict)\n",
    "    else:\n",
    "        print(f\"Polygon {idx} is mostly within another polygon and will be removed.\")\n",
    "\n",
    "# Debug: Print the number of polygons after filtering\n",
    "print(f\"Total polygons after overlap filtering: {len(filtered_polygons)}\")\n",
    "\n",
    "# Draw the filtered polygons on the image\n",
    "for poly_dict in filtered_polygons:\n",
    "    poly = poly_dict['polygon']\n",
    "    if isinstance(poly, Polygon):\n",
    "        # Handle single Polygon\n",
    "        coords = np.array(list(poly.exterior.coords)).astype(np.int32)\n",
    "        cv2.polylines(image_with_polygons, [coords], isClosed=True, color=(0, 255, 0), thickness=5)\n",
    "        polygons_list.append(poly)\n",
    "    elif isinstance(poly, MultiPolygon):\n",
    "        # Handle MultiPolygon\n",
    "        for sub_poly in poly.geoms:\n",
    "            if sub_poly.is_valid and not sub_poly.is_empty:\n",
    "                coords = np.array(list(sub_poly.exterior.coords)).astype(np.int32)\n",
    "                cv2.polylines(image_with_polygons, [coords], isClosed=True, color=(0, 255, 0), thickness=5)\n",
    "                polygons_list.append(sub_poly)\n",
    "\n",
    "# Display the image with vectorized polygons\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.imshow(cv2.cvtColor(image_with_polygons, cv2.COLOR_BGR2RGB))\n",
    "plt.title(\"Image with Filtered Polygons (Smoothed Contours)\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (conda_env)",
   "language": "python",
   "name": "conda_env"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
